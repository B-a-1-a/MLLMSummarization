{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "411f148e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    Pipeline,\n",
    "    pipeline\n",
    ")\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import torch\n",
    "from rouge_score import rouge_scorer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9d4557f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = pq.read_table('./data/test-00000-of-00001.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8e6beee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"PrekshaJoon/flan-t5-finetuned-summarization\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"PrekshaJoon/flan-t5-finetuned-summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "51e596f1-a172-4e30-af24-f7358aa15699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(article, max_length=256, min_length=100, length_penalty=2.0, num_beams=16):\n",
    "    article = str(article)\n",
    "    \n",
    "    # Tokenize the article\n",
    "    inputs = tokenizer(\"summarize: \" + article, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    \n",
    "    # Generate the summary\n",
    "    summary_ids = model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        max_length=max_length,\n",
    "        min_length=min_length,\n",
    "        num_beams=num_beams,\n",
    "        length_penalty=length_penalty,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    \n",
    "    # Decode the summary\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3df1e66b-f9c9-4f3c-8ec2-bf945171e0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             article  \\\n",
      "0  (CNN)The Palestinian Authority officially beca...   \n",
      "1  (CNN)Never mind cats having nine lives. A stra...   \n",
      "2  (CNN)If you've been following the news lately,...   \n",
      "3  (CNN)Five Americans who were monitored for thr...   \n",
      "4  (CNN)A Duke student has admitted to hanging a ...   \n",
      "\n",
      "                                   reference_summary  \\\n",
      "0  Membership gives the ICC jurisdiction over all...   \n",
      "1  Theia, a bully breed mix, was apparently hit b...   \n",
      "2  Mohammad Javad Zarif has spent more time with ...   \n",
      "3  17 Americans were exposed to the Ebola virus w...   \n",
      "4  Student is no longer on Duke University campus...   \n",
      "\n",
      "                                   generated_summary    rouge1    rouge2  \\\n",
      "0  The Palestinian Authority officially became th...  0.323529  0.194030   \n",
      "1  A stray pooch in Washington State has used up ...  0.413793  0.175439   \n",
      "2  If you've been following the news lately, ther...  0.250000  0.106667   \n",
      "3  Five Americans who were monitored for three we...  0.363636  0.100840   \n",
      "4  A Duke student has admitted to hanging a noose...  0.478261  0.191176   \n",
      "\n",
      "     rougeL  \n",
      "0  0.294118  \n",
      "1  0.310345  \n",
      "2  0.197368  \n",
      "3  0.198347  \n",
      "4  0.275362  \n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n",
    "\n",
    "for i in range(len(dataset[\"article\"])):\n",
    "    article = str(dataset[\"article\"][i])\n",
    "    reference_summary = str(dataset[\"highlights\"][i])\n",
    "    generated_summary = str(generate_summary(article))\n",
    "    \n",
    "    # Calculate ROUGE scores\n",
    "    rouge_scores = scorer.score(reference_summary, generated_summary)\n",
    "    \n",
    "    # Store results\n",
    "    results.append({\n",
    "        \"article\": article,\n",
    "        \"reference_summary\": reference_summary,\n",
    "        \"generated_summary\": generated_summary,\n",
    "        \"rouge1\": rouge_scores[\"rouge1\"].fmeasure,\n",
    "        \"rouge2\": rouge_scores[\"rouge2\"].fmeasure,\n",
    "        \"rougeL\": rouge_scores[\"rougeL\"].fmeasure\n",
    "    })\n",
    "\n",
    "    if i == 50:\n",
    "        break\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"rouge_scores_flanT5_finetuned.csv\", index=False)\n",
    "\n",
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73d59ee8-ad4b-4bd7-8b9a-50ae711eda1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(article):\n",
    "    inputs = tokenizer(\"summarize: \" + article, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    summary_ids = model.generate(inputs[\"input_ids\"], max_length=128, num_beams=4, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8b8f66a-e1e7-42d7-a013-7eb218918099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             article  \\\n",
      "0  (CNN)The Palestinian Authority officially beca...   \n",
      "1  (CNN)Never mind cats having nine lives. A stra...   \n",
      "2  (CNN)If you've been following the news lately,...   \n",
      "3  (CNN)Five Americans who were monitored for thr...   \n",
      "4  (CNN)A Duke student has admitted to hanging a ...   \n",
      "\n",
      "                                   reference_summary  \\\n",
      "0  Membership gives the ICC jurisdiction over all...   \n",
      "1  Theia, a bully breed mix, was apparently hit b...   \n",
      "2  Mohammad Javad Zarif has spent more time with ...   \n",
      "3  17 Americans were exposed to the Ebola virus w...   \n",
      "4  Student is no longer on Duke University campus...   \n",
      "\n",
      "                                   generated_summary    rouge1    rouge2  \\\n",
      "0  ICC treaty, paving the way for war crimes inve...  0.232558  0.097561   \n",
      "1  A stray pooch in Washington State, was buried ...  0.276923  0.095238   \n",
      "2  Mohammad Javad Zarif a hero's welcome as he ar...  0.230769  0.080000   \n",
      "3  Five Americans who were monitored for three we...  0.149254  0.000000   \n",
      "4  A Duke student has admitted to hanging a noose...  0.406250  0.161290   \n",
      "\n",
      "     rougeL  \n",
      "0  0.232558  \n",
      "1  0.276923  \n",
      "2  0.230769  \n",
      "3  0.119403  \n",
      "4  0.312500  \n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n",
    "\n",
    "for i in range(len(dataset[\"article\"])):\n",
    "    article = str(dataset[\"article\"][i])\n",
    "    reference_summary = str(dataset[\"highlights\"][i])\n",
    "    generated_summary = str(generate_summary(article))\n",
    "    \n",
    "    # Calculate ROUGE scores\n",
    "    rouge_scores = scorer.score(reference_summary, generated_summary)\n",
    "    \n",
    "    # Store results\n",
    "    results.append({\n",
    "        \"article\": article,\n",
    "        \"reference_summary\": reference_summary,\n",
    "        \"generated_summary\": generated_summary,\n",
    "        \"rouge1\": rouge_scores[\"rouge1\"].fmeasure,\n",
    "        \"rouge2\": rouge_scores[\"rouge2\"].fmeasure,\n",
    "        \"rougeL\": rouge_scores[\"rougeL\"].fmeasure\n",
    "    })\n",
    "\n",
    "    if i == 50:\n",
    "        break\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"rouge_scores_flanT5_finetuned.csv\", index=False)\n",
    "\n",
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc6673d0-23dd-473f-98b5-01f1ca5e89f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 130, but your input_length is only 122. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=61)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             article  \\\n",
      "0  (CNN)The Palestinian Authority officially beca...   \n",
      "1  (CNN)Never mind cats having nine lives. A stra...   \n",
      "2  (CNN)If you've been following the news lately,...   \n",
      "3  (CNN)Five Americans who were monitored for thr...   \n",
      "4  (CNN)A Duke student has admitted to hanging a ...   \n",
      "\n",
      "                                   reference_summary  \\\n",
      "0  Membership gives the ICC jurisdiction over all...   \n",
      "1  Theia, a bully breed mix, was apparently hit b...   \n",
      "2  Mohammad Javad Zarif has spent more time with ...   \n",
      "3  17 Americans were exposed to the Ebola virus w...   \n",
      "4  Student is no longer on Duke University campus...   \n",
      "\n",
      "                                   generated_summary    rouge1    rouge2  \\\n",
      "0  The Palestinian Authority becomes the 123rd me...  0.535211  0.376812   \n",
      "1  Theia, a one-year-old bully breed mix, was hit...  0.488372  0.285714   \n",
      "2  Mohammad Javad Zarif is the Iranian foreign mi...  0.400000  0.205882   \n",
      "3  The five were exposed to Ebola in Sierra Leone...  0.394366  0.173913   \n",
      "4  The noose was found on a tree near a student u...  0.415584  0.133333   \n",
      "\n",
      "     rougeL  \n",
      "0  0.478873  \n",
      "1  0.488372  \n",
      "2  0.257143  \n",
      "3  0.338028  \n",
      "4  0.207792  \n"
     ]
    }
   ],
   "source": [
    "# Load the BART-Large-CNN summarization pipeline\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n",
    "\n",
    "# Function to summarize article with truncation\n",
    "def summarize_article(article, max_input_length=1024, max_output_length=130, min_output_length=30):\n",
    "    \"\"\"\n",
    "    Summarize the article while ensuring input length constraints.\n",
    "    \"\"\"\n",
    "    # Truncate the article if it's too long\n",
    "    input_tokens = article.split()\n",
    "    if len(input_tokens) > max_input_length:\n",
    "        article = \" \".join(input_tokens[:max_input_length])\n",
    "\n",
    "    # Generate summary\n",
    "    summary = summarizer(article, max_length=max_output_length, min_length=min_output_length, do_sample=False)\n",
    "    return summary[0][\"summary_text\"]\n",
    "\n",
    "# Initialize results storage\n",
    "results = []\n",
    "count = 0\n",
    "# Process each article in the dataset\n",
    "for i in range(len(dataset[\"article\"])):\n",
    "    article = str(dataset[\"article\"][i])\n",
    "    reference_summary = str(dataset[\"highlights\"][i])\n",
    "    count += 1\n",
    "\n",
    "    # Generate summary for the article\n",
    "    try:\n",
    "        generated_summary = summarize_article(article)\n",
    "    except Exception as e:\n",
    "        continue\n",
    "\n",
    "    # Calculate ROUGE scores\n",
    "    rouge_scores = scorer.score(reference_summary, generated_summary)\n",
    "\n",
    "    # Store results\n",
    "    results.append({\n",
    "        \"article\": article,\n",
    "        \"reference_summary\": reference_summary,\n",
    "        \"generated_summary\": generated_summary,\n",
    "        \"rouge1\": rouge_scores[\"rouge1\"].fmeasure,\n",
    "        \"rouge2\": rouge_scores[\"rouge2\"].fmeasure,\n",
    "        \"rougeL\": rouge_scores[\"rougeL\"].fmeasure\n",
    "    })\n",
    "\n",
    "    # Optional: Stop early for testing\n",
    "    if count == 75:\n",
    "        break\n",
    "\n",
    "# Save results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"bart_large_summaries.csv\", index=False)\n",
    "\n",
    "# Display the first few rows\n",
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2946ee9-c819-4c00-8815-b60e70d4eb96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
