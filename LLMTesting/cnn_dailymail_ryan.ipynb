{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "411f148e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    Pipeline,\n",
    ")\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import torch\n",
    "from rouge_score import rouge_scorer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9d4557f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = pq.read_table('./data/test-00000-of-00001.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8e6beee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"PrekshaJoon/flan-t5-finetuned-summarization\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"PrekshaJoon/flan-t5-finetuned-summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "51e596f1-a172-4e30-af24-f7358aa15699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(article, max_length=256, min_length=100, length_penalty=2.0, num_beams=16):\n",
    "    article = str(article)\n",
    "    \n",
    "    # Tokenize the article\n",
    "    inputs = tokenizer(\"summarize: \" + article, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    \n",
    "    # Generate the summary\n",
    "    summary_ids = model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        max_length=max_length,\n",
    "        min_length=min_length,\n",
    "        num_beams=num_beams,\n",
    "        length_penalty=length_penalty,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    \n",
    "    # Decode the summary\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3df1e66b-f9c9-4f3c-8ec2-bf945171e0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             article  \\\n",
      "0  (CNN)The Palestinian Authority officially beca...   \n",
      "1  (CNN)Never mind cats having nine lives. A stra...   \n",
      "2  (CNN)If you've been following the news lately,...   \n",
      "3  (CNN)Five Americans who were monitored for thr...   \n",
      "4  (CNN)A Duke student has admitted to hanging a ...   \n",
      "\n",
      "                                   reference_summary  \\\n",
      "0  Membership gives the ICC jurisdiction over all...   \n",
      "1  Theia, a bully breed mix, was apparently hit b...   \n",
      "2  Mohammad Javad Zarif has spent more time with ...   \n",
      "3  17 Americans were exposed to the Ebola virus w...   \n",
      "4  Student is no longer on Duke University campus...   \n",
      "\n",
      "                                   generated_summary    rouge1    rouge2  \\\n",
      "0  The Palestinian Authority officially became th...  0.323529  0.194030   \n",
      "1  A stray pooch in Washington State has used up ...  0.413793  0.175439   \n",
      "2  If you've been following the news lately, ther...  0.250000  0.106667   \n",
      "3  Five Americans who were monitored for three we...  0.363636  0.100840   \n",
      "4  A Duke student has admitted to hanging a noose...  0.478261  0.191176   \n",
      "\n",
      "     rougeL  \n",
      "0  0.294118  \n",
      "1  0.310345  \n",
      "2  0.197368  \n",
      "3  0.198347  \n",
      "4  0.275362  \n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for i in range(len(dataset[\"article\"])):\n",
    "    article = str(dataset[\"article\"][i])\n",
    "    reference_summary = str(dataset[\"highlights\"][i])\n",
    "    generated_summary = str(generate_summary(article))\n",
    "    \n",
    "    # Calculate ROUGE scores\n",
    "    rouge_scores = scorer.score(reference_summary, generated_summary)\n",
    "    \n",
    "    # Store results\n",
    "    results.append({\n",
    "        \"article\": article,\n",
    "        \"reference_summary\": reference_summary,\n",
    "        \"generated_summary\": generated_summary,\n",
    "        \"rouge1\": rouge_scores[\"rouge1\"].fmeasure,\n",
    "        \"rouge2\": rouge_scores[\"rouge2\"].fmeasure,\n",
    "        \"rougeL\": rouge_scores[\"rougeL\"].fmeasure\n",
    "    })\n",
    "\n",
    "    if i == 50:\n",
    "        break\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"rouge_scores_flanT5_finetuned.csv\", index=False)\n",
    "\n",
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d59ee8-ad4b-4bd7-8b9a-50ae711eda1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
